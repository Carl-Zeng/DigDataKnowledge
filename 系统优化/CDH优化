Cloudera平台优化
1 优化内容
平台优化的目的包括平台运行稳定、资源利用率高、平台数据安全等。

2 平台运行合理稳定
平台本身以及包含的Hadoop组件部署的不合理，会导致平台运行状态不稳定，各种问题与报警不断。常见的问题
包括数据目录或者log目录使用100%导致节点不可用，网络瓶颈等。
常采用的优化手段：
1）采用合理的角色分配方案
在角色分配时，管理节点、主节点、数据节点、边缘节点必须明确的分开。不同的组件角色应当运行在准确的
节点上，分配混乱容易产生不稳定因素，也有利于其他组件的优化配置。
2）集群安装时合理的挂在与分配disk
不同的角色对硬盘的空间以及访问频率是不一样的，对安全性要求也不一样。对于高频访问硬盘的角色，在每个节点
上建议分配独立的disk，这类角色包括NameNode元数据目录、zookeeper数据目录、Datanode数据目录等。
3）保证必要、合理的Log目录大小
各个角色都有默认的log存储策略，其对应一定的存储空间，当节点上log回收不及时或者存储空间被其他
应用占用，会影响平台组件的运行。
4）节点硬件配置
对于同一类型的节点，建议硬件采用统一的配置。
5）合理选择gataway节点
有条件时，可以选择单独一台机子作为gataway节点，用于访问集群与任务的提交。这样做的好处是1>避免运行任务
过多，占用太多的资源，影响集群的运行，常见的如SparkDriver或者机器学习的任务，会占用大量的内存以及CPU。
2>本地任务可能占用log目录的空间；3>向HDFS写入数据时不会产生单个节点的数据堆积；
4>错误操作影响范围小，如误删目录等，以及不合理的权限修改。
6）合理的内存参数分配
各个角色对内存的要求是不同的，差异化的设置有利于各角色的运行。
7)系统参数设置
禁止使用vm.swappness；
关闭所有节点透明大页面，避免发生CPU使用率过高的问题；
调整机器的句柄上限；



3 集群资源利用
需要规划使用的资源包括disk空间分配、内存分配、HDFS存储空间分配、Yarn计算资源分配、Impala计算资源分配。
1）disk资源分配
硬盘资源在底层需要分为两部分：系统以及临时目录空间，这部分一般认为100G就足够了、另外尽可能将多的
存储空间分配给HDFS等。这里需要注意的是Zookeeper，NameNode等需要划分单独的disk。如果部署kafka等组件，也需要
单独的存储空间。这里只有Namenodede的存储盘建议做成raid-5或者raid-1等安全配置。
2）内存分配
内存分配主要是在Impala以及yarn\HDFS\HBase之间分配。Impala需要在所有节点设置同样的内存大小，
可以通过对单个节点内存在yarn中的调整，使内存不至于浪费。
HBase以及HDFS需要考虑数据缓存的使用情况合理的设置内存。将余下的内存在Yarn以及系统预留之间灵活分配。
静态资源池参数可以很好的解决这个问题。同时需要严格控制用户自己的程序在某个节点上运行，造成内存占用
的不可控。对于一个没有使用HBase的集群，建议可以将70%以上的内存分配给Impala，系统预留30G（实际根据角色情况而定）
足够了。
3）yarn资源配置
yarn的资源为虚拟的Vcore以及内存，每个节点合理的资源数应根据可用内存而定。虚拟内核最多应按内存
1V:1G配置，当内存较多时，可以使用1C：2VC之中配置比，不能配置太多的虚拟内核，当Yarn与Impala同时使用时，虚拟
内核数应当更少。CPU占用超过50%时Impala计算性能下降明显。
为任务分配合理的内存与CPU，向Yarn提交任务时需要设置合理的资源配置，如Mapreduce任务，单个Map数据的数据
量默认为128M，所以不会占用太多的内存，推荐2G已经够用，如果资源充足，可配到4G，当一个Map产生大量的文件，尤其是
Parquet文件是，内存需求可能超过10G，这类任务存在明显的优化空间。
提交Spark任务，单个Executor建议配置4个vcore，内存大小根据需要而定，建议1VC：4G，可根据实际情况调整。
当Yarn任务比较多时，可以采用yarnr任务队列，限制不同类型的任务资源使用上限。
4）Impala资源配置
Impala对于内存的分配粒度比较粗，需要合理的设置ImpalaPool以及mem-limit；
5）HDFS存储空间分配
对于HDFS目录空间，按照不同的应用，合理的设置目录，目的是方便潜在的权限控制，垃圾文件清楚等。
设置合理的垃圾回收时间，建议为3-4天。

4 平台数据安全 
平台数据安全内容包括三部分，平台本身元数据安全、Hive元数据安全、HDFS数据安全、访问安全。
1）平台本身元数据安全
平台的正常运行依赖于元数据库SCM，一旦发生服务器故障，可以根据元数据回复CM Server；
为了保证这部分数据安全，可以定期做数据备份，或者直接做数据库的主备机制，分别存储在两个不同的节点上。
2）Hive元数据安全
与平台元数据类似，定期备份或者元数据库主备机制。
3）HDFS数据安全
HDFS元数据存在于两个节点上，可以从Secondnamenode恢复元数据或者直接启用HA，不需要备份元数据。但是
对于数据节点，在下线或者删除时，每次只能删除少于复制因子的节点数，且要严格保证每次操作前HDFS数据块备份数
没有低于复制因子的。
4）访问安全
1>disk数据安全，应当禁止直接在Linux层面删除数据目录。
2>删除HDFS数据时将数据先移走或者放入垃圾箱中。
3>对数据的操作历史可以通过访问Namenode的审计日志查看。
